{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSI4142 - Group 48 - Assignment 2 - Part 1\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "In this report, we explore methods to identify and address common data quality issues, focusing on ten types of errors: data type errors, range errors, format errors, consistency errors, uniqueness errors, presence errors, length errors, look-up errors, exact duplicate errors, and near duplicate errors. By implementing our Clean Data Checker, we provide an automated approach to detecting these errors, allowing users to specify validation rules and parameters.\n",
    "\n",
    "Data quality is a critical factor in ensuring the reliability and usability of information stored in databases. Poor data quality can lead to incorrect analyses, flawed decision-making, and inefficiencies in various domains, including business, healthcare, and research. As organizations increasingly rely on large datasets, maintaining high-quality data through systematic validation and cleaning techniques becomes essential.\n",
    "\n",
    "Our analysis is conducted on the café sales dataset & an altered version of the cafe sales dataset. We specify which is being used in the heading of the test. \n",
    "\n",
    "\n",
    "\n",
    "#### Group 48 Members\n",
    "- Ali Bhangu - 300234254\n",
    "- Justin Wang - 300234186\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Descriptions\n",
    "\n",
    "### Café Sales Dataset\n",
    "\n",
    "- **Dataset Name:** Dirty Café Sales Dataset\n",
    "- **Author:** Ahmed Mohamed (Kaggle)\n",
    "- **Purpose:** This dataset was created for data cleaning training, containing real-world transactional data with common data quality issues such as missing values, duplicates, and inconsistent formats.\n",
    "\n",
    "##### Dataset Shape\n",
    "- **Rows:** 10000 Rows\n",
    "- **Columns:** 8 Columns \n",
    "\n",
    "#### Features & Descriptions\n",
    "| Feature Name       | Data Type  | Category    | Description |\n",
    "|--------------------|-----------|------------|-------------|\n",
    "| `Transaction ID`  | String     | Categorical | Unique identifier for each transaction |\n",
    "| `Item`            | String     | Categorical | Name of the purchased item |\n",
    "| `Quantity`        | String    | Numerical   | Number of units purchased |\n",
    "| `Price Per Unit`  | Float      | Numerical   | Cost per single unit of the item |\n",
    "| `Total Spent`     | Float      | Numerical   | Total amount spent on the transaction (Quantity × Price Per Unit) |\n",
    "| `Payment Method`  | String     | Categorical | Payment type (e.g., Cash, Credit Card) |\n",
    "| `Location`        | String     | Categorical | Café branch where the transaction took place |\n",
    "| `Transaction Date`| String       | Categorical | Date when the transaction occurred |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Python libraries\n",
    "import numpy as npy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz\n",
    "import os as os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing dirty_cafe_sales.csv found. Deleting and re-extracting...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  110k  100  110k    0     0   234k      0 --:--:-- --:--:-- --:--:--  234k\n",
      "Extracting dataset...\n",
      "Archive:  cafe-sales-dirty-data.zip\n",
      "  inflating: ./dirty_cafe_sales.csv  \n",
      "Dataset loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID    Item Quantity Price Per Unit Total Spent  Payment Method  \\\n",
       "0    TXN_1961373  Coffee        2            2.0         4.0     Credit Card   \n",
       "1    TXN_4977031    Cake        4            3.0        12.0            Cash   \n",
       "2    TXN_4271903  Cookie        4            1.0       ERROR     Credit Card   \n",
       "3    TXN_7034554   Salad        2            5.0        10.0         UNKNOWN   \n",
       "4    TXN_3160411  Coffee        2            2.0         4.0  Digital Wallet   \n",
       "\n",
       "   Location Transaction Date  \n",
       "0  Takeaway       2023-09-08  \n",
       "1  In-store       2023-05-16  \n",
       "2  In-store       2023-07-19  \n",
       "3   UNKNOWN       2023-04-27  \n",
       "4  In-store       2023-06-11  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download Function for the Cafe Dataset\n",
    "\n",
    "# Define paths\n",
    "zip_path = \"cafe-sales-dirty-data.zip\"\n",
    "csv_path = \"dirty_cafe_sales.csv\"\n",
    "\n",
    "# Delete existing CSV if present\n",
    "if os.path.exists(csv_path):\n",
    "    print(f\"Existing {csv_path} found. Deleting and re-extracting...\")\n",
    "    os.remove(csv_path)\n",
    "\n",
    "# Download dataset using curl (Bash command in Jupyter Notebook)\n",
    "!curl -L -o {zip_path} https://www.kaggle.com/api/v1/datasets/download/ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training\n",
    "\n",
    "# Extract the ZIP file in the current folder\n",
    "print(\"Extracting dataset...\")\n",
    "!unzip -o {zip_path} -d .\n",
    "\n",
    "# Verify that the CSV exists after extraction\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found: {csv_path}. Ensure the ZIP file was correctly extracted.\")\n",
    "\n",
    "# Load dataset\n",
    "cafeSet = pd.read_csv(csv_path)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "cafeSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>Ali</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID    Item Quantity Price Per Unit Total Spent Payment Method  \\\n",
       "0    TXN_1961373  Coffee        2            Ali         4.0    Credit Card   \n",
       "1    TXN_1961373  Coffee        2            2.0         4.0    Credit Card   \n",
       "2    TXN_1961373  Coffee        2            2.0         4.0    Credit Card   \n",
       "3    TXN_4977031    Cake        4            3.0        12.0           Cash   \n",
       "4    TXN_4271903  Cookie        4            1.0       ERROR    Credit Card   \n",
       "\n",
       "   Location Transaction Date  \n",
       "0  Takeaway       2023-09-08  \n",
       "1  Takeaway       2023-09-08  \n",
       "2  Takeaway       2023-09-08  \n",
       "3  In-store       2023-05-16  \n",
       "4  In-store       2023-07-19  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the altered dataset for the Cafe Sales Dataset\n",
    "\n",
    "# Changes to the dataset:\n",
    "# 1. Duplicated Transaction ID Values\n",
    "# 2. Duplicated some rows of the dataset for the exact duplicate check. \n",
    "alteredCafeSet = pd.read_csv(\"altered_dirty_cafe_sales.csv\")\n",
    "alteredCafeSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Type Error - Using Cafe Dataset\n",
    "This is our first type of check, this is a data type check, which will make sure that the data entered into a field is respective of the typing of that column. \n",
    "\n",
    "### How To Use:\n",
    "1. Enter and run parameters\n",
    "2. Run function with comment \"Data Type Test\" \n",
    "3. See results below above mentioned code block\n",
    "\n",
    "### Parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction ID      float64\n",
      "Item                 object\n",
      "Quantity             object\n",
      "Price Per Unit      float64\n",
      "Total Spent          object\n",
      "Payment Method       object\n",
      "Location             object\n",
      "Transaction Date     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "attributes = ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "print(cafeSet.dtypes)\n",
    "# Please enter the various attributes below to perform the data cleaning process on the dataset:\n",
    " \n",
    "# Input your column from the above list. \n",
    "testColumn = attributes[3]\n",
    "# Change the expected data type of the column\n",
    "expectedType = float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking column: Price Per Unit (Expected type: float)\n",
      "The Data Type Checker found 533 incorrect entries in 'Price Per Unit'. \n",
      "For Example, here are some of the problem entries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price Per Unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price Per Unit\n",
       "56              NaN\n",
       "65              NaN\n",
       "68              NaN\n",
       "85              NaN\n",
       "104             NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cake</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sandwich</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tea</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Cash</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Juice</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9924</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Juice</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9926</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9961</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tea</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Transaction ID      Item Quantity  Price Per Unit Total Spent  \\\n",
       "56               NaN      Cake      5.0             NaN        15.0   \n",
       "65               NaN  Sandwich      3.0             NaN         NaN   \n",
       "68               NaN     Salad      2.0             NaN        10.0   \n",
       "85               NaN       Tea      3.0             NaN         4.5   \n",
       "104              NaN     Juice      2.0             NaN         6.0   \n",
       "...              ...       ...      ...             ...         ...   \n",
       "9924             NaN     Juice      2.0             NaN         6.0   \n",
       "9926             NaN      Cake      4.0             NaN        12.0   \n",
       "9961             NaN       Tea      2.0             NaN         3.0   \n",
       "9996             NaN       NaN      3.0             NaN         3.0   \n",
       "9998             NaN    Cookie      3.0             NaN         3.0   \n",
       "\n",
       "      Payment Method  Location Transaction Date  \n",
       "56               nan  Takeaway       2023-06-27  \n",
       "65               nan  In-store       2023-10-20  \n",
       "68               nan  In-store       2023-10-27  \n",
       "85              Cash   UNKNOWN       2023-10-29  \n",
       "104              nan       NaN              NaN  \n",
       "...              ...       ...              ...  \n",
       "9924  Digital Wallet       NaN       2023-12-24  \n",
       "9926  Digital Wallet  Takeaway       2023-11-09  \n",
       "9961            Cash       NaN       2023-12-29  \n",
       "9996  Digital Wallet       NaN       2023-06-02  \n",
       "9998  Digital Wallet       NaN       2023-12-02  \n",
       "\n",
       "[533 rows x 8 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Type Test\n",
    "def data_type_checker(df, column, expected_type):\n",
    "     # Convert the column to expected type (ignoring errors for detection)\n",
    "    def is_expected_type(value):\n",
    "        if pd.isna(value):  \n",
    "            return False  \n",
    "        try:\n",
    "            return isinstance(eval(str(value)), expected_type)\n",
    "        except:\n",
    "            return False \n",
    "\n",
    "    # This bit identifies the incorrect entries, making a new dataframe. \n",
    "    incorrect_types = df[~df[column].apply(is_expected_type)]\n",
    "\n",
    "    # This right here controls the output for the reader of our report to see and understand. \n",
    "    print(f\"Checking column: {column} (Expected type: {expected_type.__name__})\")\n",
    "    if incorrect_types.empty:\n",
    "        print(f\"The Data Type Checker suggests all values in '{column}' match the expected data type.\")\n",
    "    else:\n",
    "        # This outputs using the values set as parameters in the sentence. \n",
    "        print(f\"The Data Type Checker found {len(incorrect_types)} incorrect entries in '{column}'. \\nFor Example, here are some of the problem entries:\")\n",
    "        display(incorrect_types[[column]].head(5))  # Here we showcase some of the incorrect entries for the user.\n",
    "\n",
    "    return incorrect_types\n",
    "\n",
    "# This starts the program and runs the function\n",
    "data_type_checker(cafeSet, testColumn, expectedType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Range Error - Using Cafe Sales Dataset\n",
    "\n",
    "In this test, we will determine whether the numerical input data falls within a given range for a specific column. The range is the maximum and minimum values that an attribute can have, and any values outside of this range are deemed in-correct. \n",
    "\n",
    "### How To Use:\n",
    "1. Enter parameters in the code block below\n",
    "2. Then run the code block. \n",
    "3. After that run the function annotated with the comment \"Range Checker Test\" and see the results outputted. \n",
    "\n",
    "### Parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of NUMERICAL columns from the dataset, please select below which one you would like to perform the range check on:\n",
    "attributes = ['Quantity', 'Price Per Unit', 'Total Spent']\n",
    "\n",
    "# Please enter the column you would like to run the range check on:\n",
    "test_attribute = attributes[1]\n",
    "\n",
    "# Please specify the minimum and maximum values for the range check: \n",
    "minimum = 2\n",
    "maximum = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2276 data points with Price Per Unit less than 2, and 1204 data points with Price Per Unit over 4.\n",
      "\n",
      "Examples below minimum:\n",
      "   Transaction ID    Item Quantity Price Per Unit Total Spent Payment Method  \\\n",
      "2     TXN_4271903  Cookie        4            1.0       ERROR    Credit Card   \n",
      "13    TXN_9437049  Cookie        5            1.0         5.0            NaN   \n",
      "\n",
      "    Location Transaction Date  \n",
      "2   In-store       2023-07-19  \n",
      "13  Takeaway       2023-06-01  \n",
      "\n",
      "Examples above maximum:\n",
      "   Transaction ID   Item Quantity Price Per Unit Total Spent Payment Method  \\\n",
      "3     TXN_7034554  Salad        2            5.0        10.0        UNKNOWN   \n",
      "10    TXN_2548360  Salad        5            5.0        25.0           Cash   \n",
      "\n",
      "    Location Transaction Date  \n",
      "3    UNKNOWN       2023-04-27  \n",
      "10  Takeaway       2023-11-07  \n"
     ]
    }
   ],
   "source": [
    "# Range Checker Test \n",
    "def range_checker(df, column, minimum, maximum):\n",
    "    # Converts columns to a numeric format, just to be sure. \n",
    "    numeric_col = pd.to_numeric(df[column], errors='coerce')\n",
    "    \n",
    "    # Filters here using the values inputted by the user to then comb through the dataset. \n",
    "    below_min = df.loc[(numeric_col < minimum) & numeric_col.notna()]\n",
    "    above_max = df.loc[(numeric_col > maximum) & numeric_col.notna()]\n",
    "    \n",
    "    # these variables will help with the output statements \n",
    "    total_below = below_min.shape[0]\n",
    "    total_above = above_max.shape[0]\n",
    "    \n",
    "    # General Print Statement: \n",
    "    print(f\"There are {total_below} data points with {column} less than {minimum}, and {total_above} data points with {column} over {maximum}.\")\n",
    "    \n",
    "    # Specific statements to print examples:\n",
    "    if total_below > 0:\n",
    "        print(\"\\For Example: Rows with values below minimum:\")\n",
    "        print(below_min.head(2))  # Show first 2 rows\n",
    "    \n",
    "    if total_above > 0:\n",
    "        print(\"\\nFor Example: Rows with values above maximum:\")\n",
    "        print(above_max.head(2))  # Show first 2 rows\n",
    "\n",
    "# Running the function to showcase usage\n",
    "range_checker(cafeSet, test_attribute, minimum, maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Format Errors - Using Cafe Sales Dataset\n",
    "\n",
    "Within this section, we are testing for format errors. A Format Check will ensure that the data is in an acceptable format, such as dates are written in YYYY-MM-DD or DD-MM-YYYY. If this format is violated, it will return with the violating returns and provide a summarized output. \n",
    "\n",
    "### How To Use:\n",
    "1. Enter Parameters in Code Block below\n",
    "2. Enter Regex Pattern for the Format Pattern \n",
    "3. Run the Parameters Code Block\n",
    "4. Run the code block, annotated with \"Format Check Test\". \n",
    "\n",
    "### Parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please enter the various attributes below to perform the data cleaning process on the dataset. \n",
    "attributes = ['Transaction Date', 'Transaction Time', 'Card Number', 'Transaction ID']\n",
    "\n",
    "# Input your column \n",
    "column = attributes[0]\n",
    "\n",
    "# Please enter the regex pattern you would like to check for\n",
    "pattern = r'^\\d{4}-\\d{2}-\\d{2}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 460 data points in Transaction Date that do not match the format ^\\d{4}-\\d{2}-\\d{2}$. \n",
      "See below for examples if there are mismatched rows:\n",
      "\n",
      "Here are some of the rows of mismatched format:\n",
      "   Transaction ID      Item  Quantity  Price Per Unit  Total Spent  \\\n",
      "11    TXN_3051279  Sandwich       2.0             4.0          8.0   \n",
      "29    TXN_7640952      Cake       4.0             3.0         12.0   \n",
      "33    TXN_7710508   UNKNOWN       5.0             1.0          5.0   \n",
      "\n",
      "    Payment Method  Location Transaction Date  expected_value  expected_total  \n",
      "11     Credit Card  Takeaway            ERROR             8.0             8.0  \n",
      "29  Digital Wallet  Takeaway            ERROR            12.0            12.0  \n",
      "33            Cash       NaN            ERROR             5.0             5.0  \n"
     ]
    }
   ],
   "source": [
    "# Format Check Test: \n",
    "\n",
    "def format_checker(df, column, pattern):\n",
    "    # creating the regex pattern\n",
    "    regex = re.compile(pattern)\n",
    "    \n",
    "    # Applying the regex pattern to the column and filters the rows that don't match\n",
    "    mismatched_rows = df[~df[column].astype(str).apply(lambda x: bool(regex.match(x)))]\n",
    "    total_mismatched = mismatched_rows.shape[0]\n",
    "    \n",
    "    # Printing the results of the format check. \n",
    "    print(f\"There are {total_mismatched} data points in {column} that do not match the format {pattern}. \\nSee below for examples if there are mismatched rows:\")\n",
    "    \n",
    "    # Outputting the mismatched rows for the user to see\n",
    "    if total_mismatched > 0:\n",
    "        print(\"\\nHere are some of the rows of mismatched format:\")\n",
    "        print(mismatched_rows.head(3))  \n",
    "\n",
    "# Running the function with parameters defined above:\n",
    "format_checker(cafeSet, column, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Consistency Errors - Using Cafe Sales Data Set\n",
    "\n",
    "Within this section we will run a consistency check test, a consistency check is defined as a logical check that ensures data is consistent and makes sense. For example, checking if the date of a show added is after its release date. Find this test in the code block annoted with \"Consistency Checker Test\"\n",
    "\n",
    "### How To Use:\n",
    "1. Enter Parameters in Code Block below\n",
    "2. Run the parameters code block \n",
    "3. Run the code block for the function that will test the consistency. \n",
    "\n",
    "### Parameters: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please enter the various attrivutes below to perform the data cleaning process on the dataset. \n",
    "attributes = ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "# You can run the consistency checker against two columns or with two against 1. \n",
    "# Example usage: Checking if Quantity x Price Per Unit = Total Spent\n",
    "test_attribute_1 = attributes[2]\n",
    "test_attribute_2 = attributes[3]\n",
    "test_attribute_3 = attributes[4]\n",
    "\n",
    "#If True, checks if test_attribute_1 == test_attribute_2.\n",
    "# If False, checks if test_attribute_1 * test_attribute_2 == test_attribute_3.\n",
    "compare_two_columns = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1456 consistency errors for check: Quantity * Price Per Unit != Total Spent. See for example the following rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>expected_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quantity  Price Per Unit  Total Spent  expected_value\n",
       "2        4.0             1.0          NaN             4.0\n",
       "20       NaN             4.0         20.0             NaN\n",
       "25       3.0             4.0          NaN            12.0\n",
       "31       2.0             1.0          NaN             2.0\n",
       "42       2.0             1.5          NaN             3.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "      <th>expected_value</th>\n",
       "      <th>expected_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TXN_3522028</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TXN_7958992</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-12-13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TXN_8927252</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TXN_6650263</td>\n",
       "      <td>Tea</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>TXN_3142496</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>TXN_9594133</td>\n",
       "      <td>Cake</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>TXN_4766549</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>TXN_9659401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>TXN_7695629</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1456 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Transaction ID      Item  Quantity  Price Per Unit  Total Spent  \\\n",
       "2       TXN_4271903    Cookie       4.0             1.0          NaN   \n",
       "20      TXN_3522028  Smoothie       NaN             4.0         20.0   \n",
       "25      TXN_7958992  Smoothie       3.0             4.0          NaN   \n",
       "31      TXN_8927252   UNKNOWN       2.0             1.0          NaN   \n",
       "42      TXN_6650263       Tea       2.0             1.5          NaN   \n",
       "...             ...       ...       ...             ...          ...   \n",
       "9984    TXN_3142496  Smoothie       NaN             4.0          4.0   \n",
       "9988    TXN_9594133      Cake       5.0             3.0          NaN   \n",
       "9993    TXN_4766549  Smoothie       2.0             4.0          NaN   \n",
       "9996    TXN_9659401       NaN       3.0             NaN          3.0   \n",
       "9998    TXN_7695629    Cookie       3.0             NaN          3.0   \n",
       "\n",
       "      Payment Method  Location Transaction Date  expected_value  \\\n",
       "2        Credit Card  In-store       2023-07-19             4.0   \n",
       "20              Cash  In-store       2023-04-04             NaN   \n",
       "25           UNKNOWN   UNKNOWN       2023-12-13            12.0   \n",
       "31       Credit Card     ERROR       2023-11-06             2.0   \n",
       "42               NaN  Takeaway       2023-01-10             3.0   \n",
       "...              ...       ...              ...             ...   \n",
       "9984            Cash  Takeaway       2023-07-27             NaN   \n",
       "9988           ERROR       NaN              NaN            15.0   \n",
       "9993            Cash       NaN       2023-10-20             8.0   \n",
       "9996  Digital Wallet       NaN       2023-06-02             NaN   \n",
       "9998  Digital Wallet       NaN       2023-12-02             NaN   \n",
       "\n",
       "      expected_total  \n",
       "2                4.0  \n",
       "20               NaN  \n",
       "25              12.0  \n",
       "31               2.0  \n",
       "42               3.0  \n",
       "...              ...  \n",
       "9984             NaN  \n",
       "9988            15.0  \n",
       "9993             8.0  \n",
       "9996             NaN  \n",
       "9998             NaN  \n",
       "\n",
       "[1456 rows x 10 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consistency Checker Test\n",
    "def consistency_checker(df, column_1, column_2, expected_column=None, compare_two=False):\n",
    "    # Convert specified columns to numeric as we did above \n",
    "    df[column_1] = pd.to_numeric(df[column_1], errors='coerce')\n",
    "    df[column_2] = pd.to_numeric(df[column_2], errors='coerce')\n",
    "    \n",
    "    # Check if comparing two columns or two columns against one\n",
    "    if compare_two:\n",
    "        # Compare two columns directly for equality\n",
    "        inconsistent = df[df[column_1] != df[column_2]]\n",
    "        # Formatting the string check type for the output\n",
    "        check_type = f\"{column_1} != {column_2}\"\n",
    "    \n",
    "    # If there is no expected column, raise an error for the user\n",
    "    else:\n",
    "        if expected_column is None:\n",
    "            raise ValueError(\"You must provide an expected column when compare_two=False.\")\n",
    "        \n",
    "        # Otherwise we convert it to numeric and then check if the expected column is equal to the product of the two columns\n",
    "        df[expected_column] = pd.to_numeric(df[expected_column], errors='coerce')\n",
    "        df['expected_value'] = df[column_1] * df[column_2]\n",
    "        inconsistent = df[df[expected_column] != df['expected_value']]\n",
    "        check_type = f\"{column_1} * {column_2} != {expected_column}\"\n",
    "    \n",
    "    # Again, here we display results according to the findings\n",
    "    if inconsistent.empty:\n",
    "        print(f\"No consistency errors found for check: {check_type}.\")\n",
    "    else:\n",
    "        print(f\"There are {len(inconsistent)} consistency errors for check: {check_type}. See for example the following rows:\")\n",
    "        display_cols = [column_1, column_2]\n",
    "        if not compare_two:\n",
    "            display_cols.append(expected_column)\n",
    "            display_cols.append('expected_value')\n",
    "        display(inconsistent[display_cols].head())  \n",
    "\n",
    "    return inconsistent\n",
    "\n",
    "# Running Function\n",
    "consistency_checker(cafeSet, test_attribute_1, test_attribute_2, test_attribute_3, compare_two_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Uniqueness Errors - Using Altered Cafe Sales Dataset\n",
    "\n",
    "Within this section, we will be testing for Uniqueness errors. A uniqueness error is pretty much when there is inherently unique data such as IDs or E-Mails in a database. Our tester below, annoted with the comment \"Uniqueness Check Function\" will run and ensure that an item is not entered into a database more than once. \n",
    "\n",
    "This section uses an <strong>altered version</strong> of the cafe sales dataset, within that altered version there are duplicates of the transaction ID, and some rows. \n",
    "\n",
    "### How To Use:\n",
    "1. Input parameters and run code block\n",
    "2. Run code block with Comment: \"Unqiueness Checker Test\" \n",
    "3. See results \n",
    "\n",
    "### Parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes to choose from: \n",
    "attributes = ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "# Please enter the column you would like to perform the uniqueness check on from the above list: \n",
    "testColumn = attributes[0]\n",
    "\n",
    "# Specify the dataset you would like to perform the uniqueness check on (cafeSet or alteredCafeSet):\n",
    "dataFrame = alteredCafeSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 duplicate entries in the 'Transaction ID' column. Here are some examples of the duplicate entries:\n",
      "   Transaction ID\n",
      "0     TXN_1961373\n",
      "3     TXN_1961373\n",
      "10    TXN_2548360\n",
      "21    TXN_2548360\n",
      "27    TXN_5695074\n",
      "36    TXN_6855453\n",
      "37    TXN_1080432\n",
      "38    TXN_1080432\n",
      "43    TXN_5695074\n",
      "46    TXN_6855453\n",
      "47    TXN_8078640\n",
      "48    TXN_8201146\n",
      "50    TXN_8201146\n",
      "52    TXN_8078640\n"
     ]
    }
   ],
   "source": [
    "# Uniqueness Checker Test\n",
    "def uniqueness_checker(df, column):\n",
    "    # Find duplicates in the specified column\n",
    "    duplicates = df[df.duplicated(subset=[column], keep=False)]\n",
    "    \n",
    "    # Output results\n",
    "    if duplicates.empty:\n",
    "        print(f\"All values in '{column}' are unique.\")\n",
    "    else:\n",
    "        print(f\"Found {len(duplicates)} duplicate entries in the '{column}' column. Here are some examples of the duplicate entries:\")\n",
    "        print(duplicates[[column]].head(len(duplicates)))  \n",
    "        \n",
    "    return duplicates\n",
    "\n",
    "# Example usage:\n",
    "duplicates = uniqueness_checker(dataFrame, testColumn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Presence Errors - Using Cafe Dataset\n",
    "\n",
    "This section of the report will be focusing on the presence errors that are present. A presence check is defined as a check that ensures that all mandatory fields are not left blank. Our checker takes a column as input and will run the presence checker on the specified attribute. \n",
    "\n",
    "### How To Use: \n",
    "1. Input desired attribute from list\n",
    "2. Run attribute code block\n",
    "3. Run the code block annotated with this comment: \"Presence Checker Test\" \n",
    "\n",
    "### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "# Please specify the column from the above list:\n",
    "testColumn = attributes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of the presence check are as follows: There are 677 missing values in 'Item'. \n",
      "For Example:\n",
      "         Item\n",
      "6     UNKNOWN\n",
      "8         NaN\n",
      "30        NaN\n",
      "31    UNKNOWN\n",
      "33    UNKNOWN\n",
      "...       ...\n",
      "9876      NaN\n",
      "9885      NaN\n",
      "9946  UNKNOWN\n",
      "9994  UNKNOWN\n",
      "9996      NaN\n",
      "\n",
      "[677 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Presence Checker Test\n",
    "def presence_checker(df, column):\n",
    "    \n",
    "    # Checks if the column has any missing values or unknown entries as they exist in the dataset. \n",
    "    missing = df[df[column].isna() | (df[column].str.lower() == 'unknown')]\n",
    "    \n",
    "    # If there is nothing \n",
    "    if missing.empty:\n",
    "        print(f\"The results of the presence checker indicate that there are no missing values found in '{column}'.\")\n",
    "    else:\n",
    "        # Showcase the results in the dataset. \n",
    "        print(f\"The results of the presence check are as follows: There are {len(missing)} missing values in '{column}'. \\nFor Example:\")\n",
    "        print(missing[[column]].head(len(missing)))  \n",
    "    \n",
    "    return missing\n",
    "\n",
    "\n",
    "# Running the function:\n",
    "missing_values = presence_checker(cafeSet, testColumn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Length Errors - Using Cafe Dataset\n",
    "This section is for a length check, which is a check that determines if the right amount of characters are entered into a field. Below we have our parameters which can be altered, a user can specify the desired attribute and the testLength. \n",
    "\n",
    "### How To Use\n",
    "1. Enter parameters and run the code block\n",
    "2. Run the code block with the comment \"Length Checker Test\" \n",
    "3. See results in the cell below the code block. \n",
    "\n",
    "### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "# Select from the list above the column you would like to perform the length check on:\n",
    "testColumn = attributes[4]\n",
    "\n",
    "# Enter the length you would like to check for:\n",
    "testLength = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length checker test indicates that there are 3975 entries in 'Total Spent' that do not meet the length requirement of 3. \n",
      "For Example:\n",
      "  Total Spent\n",
      "1        12.0\n",
      "2       ERROR\n",
      "3        10.0\n",
      "5        20.0\n",
      "7        16.0\n"
     ]
    }
   ],
   "source": [
    "# Length Checker Test: \n",
    "def length_checker(df, column, length):\n",
    "    # Converting the column to string and checking its length\n",
    "    invalid_length = df[df[column].astype(str).str.len() != length]\n",
    "    \n",
    "    # Formatting the findings of the function to be results for the reader. \n",
    "    if invalid_length.empty:\n",
    "        print(f\"The length checker test suggests that all values in '{column}' meet the length requirement of {length}.\")\n",
    "    else:\n",
    "        print(f\"The length checker test indicates that there are {len(invalid_length)} entries in '{column}' that do not meet the length requirement of {length}. \\nFor Example:\")\n",
    "        print(invalid_length[[column]].head(5))  # Display first 5 invalid entries\n",
    "    \n",
    "    return invalid_length\n",
    "\n",
    "# Running the test: \n",
    "invalid_length = length_checker(cafeSet, testColumn, testLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Look-Up Errors - Using Cafe Dataset\n",
    "\n",
    "This section is devoted to look-up errors. For our look-up check, we take the desired test column and then valid values of the column. It will then look through the dataset and return invalid entries.\n",
    "\n",
    "### How To Use\n",
    "1. Enter parameters and run the code block \n",
    "2. Run the code block labelled with \"Look-Up Test\" \n",
    "3. See results in the cell below the labelled code block. \n",
    "\n",
    "### Parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "# Pleaase enter the desired column from the list above to perform the data cleaning process on the dataset.\n",
    "testColumn = attributes[5]\n",
    "\n",
    "# Please enter the list of valid values for the selected column:\n",
    "validValues = [\"Credit Card\", \"Cash\", \"Digital Wallet\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3178 invalid entries in 'Payment Method' for these specified values: ['Credit Card', 'Cash', 'Digital Wallet']. \n",
      "For Example:\n",
      "   Payment Method\n",
      "3         UNKNOWN\n",
      "6           ERROR\n",
      "8             NaN\n",
      "9             NaN\n",
      "13            NaN\n",
      "14            NaN\n"
     ]
    }
   ],
   "source": [
    "# Look-Up Test\n",
    "def lookup_checker(df, column, valid_values):\n",
    "    # Check for invalid values in the column\n",
    "    invalid_values = df[~df[column].isin(valid_values)]\n",
    "    \n",
    "    # Formatting the results for the invalid_values, either if its empty or if there were found\n",
    "    if invalid_values.empty:\n",
    "        print(f\"The look-up test insists that all values in '{column}' are valid to the provided vales {valid_values}.\")\n",
    "    else:\n",
    "        print(f\"Found {len(invalid_values)} invalid entries in '{column}' for these specified values: {valid_values}. \\nFor Example:\")\n",
    "        print(invalid_values[[column]].head(6))  # Display first 6 invalid entries\n",
    "    \n",
    "    return invalid_values\n",
    "\n",
    "\n",
    "# Run the function: \n",
    "lookup_errors = lookup_checker(cafeSet, testColumn, validValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exact Duplicate Errors - Using Altered Cafe Dataset\n",
    "\n",
    "This section will focus on exact duplicates, primarily at a row and record-level. Meaning records that are exactly the same.  \n",
    "\n",
    "### How To Use:\n",
    "1. Input parameters below\n",
    "2. Run the parameters code block\n",
    "3. Navigate to the code block below the parameters one, identifiable by the comment at the top \"Exact Duplicate Checker Test\n",
    "\" \n",
    "4. Run the code block and see the results. \n",
    "\n",
    "#### Parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "\n",
    "# Please input the columns you would like to check for an exact duplicate checker. \n",
    "columns_to_check = [attributes[0], attributes[5]]\n",
    "\n",
    "# Select the dataset. \n",
    "dataFrame = alteredCafeSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The checker indicates that there are 2 exact duplicate rows based on columns: ['Transaction ID', 'Payment Method']. \n",
      " For example, find some of the duplicate rows below:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Payment Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID Payment Method\n",
       "0    TXN_1961373    Credit Card\n",
       "1    TXN_1961373    Credit Card"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID    Item Quantity Price Per Unit Total Spent Payment Method  \\\n",
       "0    TXN_1961373  Coffee        2            2.0         4.0    Credit Card   \n",
       "1    TXN_1961373  Coffee        2            2.0         4.0    Credit Card   \n",
       "\n",
       "   Location Transaction Date  \n",
       "0  Takeaway       2023-09-08  \n",
       "1  Takeaway       2023-09-08  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exact Duplicate Checker Test\n",
    "def exact_duplicate_checker(df, subset_columns):\n",
    "    if not subset_columns:\n",
    "        raise ValueError(\"You must specify at least one column to check for exact duplicates.\")\n",
    "\n",
    "    # Find exact duplicates based on the selected columns\n",
    "    duplicates = df[df.duplicated(subset=subset_columns, keep=False)]\n",
    "\n",
    "    if duplicates.empty:\n",
    "        # If there are no duplicates, this will be the output:\n",
    "        print(f\"No exact duplicates found based on columns: {subset_columns}.\")\n",
    "    else:\n",
    "        # Creating a neat output for the results of the function. \n",
    "        print(f\"The checker indicates that there are {len(duplicates)} exact duplicate rows based on columns: {subset_columns}. \\n For example, find some of the duplicate rows below:\")\n",
    "        display(duplicates[subset_columns].head()) \n",
    "\n",
    "    return duplicates\n",
    "\n",
    "exact_duplicate_checker(dataFrame, columns_to_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Near Duplicate Errors - Using Cafe Dataset \n",
    "This is the final test in our report. It checks for near duplicate errors, which can be defined as records that are similar but not completely identical due to typos or missing values. Our implemntation allows the user to input columns to check and a difference in column they can tweak. \n",
    "\n",
    "### How To Use:\n",
    "1. Set parameters and run the code block\n",
    "2. Run code block labelled with comment \"Near Dupes Test\"\n",
    "3. See results outputted in real time below that code block. \n",
    "\n",
    "#### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "# Please enter the columns you would like to perform the data cleaning process on the dataset.\n",
    "columns_to_check = [attributes[1], attributes[4]]\n",
    "\n",
    "# Please enter a threshold value for the near duplicate checker, this will specify the percentage of similarity between the columns\n",
    "threshold = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The near duplicate test program found 4 near duplicate row pairs for the columns ['Item', 'Total Spent']. \n",
      "Here are some examples:\n",
      "\n",
      "Row 3496 ~ Row 3497 (Similarity: 93.00%)\n",
      "Row 1: {'Item': 'ERROR', 'Total Spent': '2.0'}\n",
      "Row 2: {'Item': 'ERROR', 'Total Spent': '20.0'}\n",
      "\n",
      "Row 5739 ~ Row 5740 (Similarity: 93.00%)\n",
      "Row 1: {'Item': 'Salad', 'Total Spent': '25.0'}\n",
      "Row 2: {'Item': 'Salad', 'Total Spent': '5.0'}\n",
      "\n",
      "Row 9430 ~ Row 9431 (Similarity: 93.00%)\n",
      "Row 1: {'Item': 'UNKNOWN', 'Total Spent': '2.0'}\n",
      "Row 2: {'Item': 'UNKNOWN', 'Total Spent': '20.0'}\n",
      "\n",
      "Row 9800 ~ Row 9801 (Similarity: 93.00%)\n",
      "Row 1: {'Item': 'nan', 'Total Spent': '2.0'}\n",
      "Row 2: {'Item': 'nan', 'Total Spent': '20.0'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3496,\n",
       "  3497,\n",
       "  93.0,\n",
       "  {'Item': 'ERROR', 'Total Spent': '2.0'},\n",
       "  {'Item': 'ERROR', 'Total Spent': '20.0'}),\n",
       " (5739,\n",
       "  5740,\n",
       "  93.0,\n",
       "  {'Item': 'Salad', 'Total Spent': '25.0'},\n",
       "  {'Item': 'Salad', 'Total Spent': '5.0'}),\n",
       " (9430,\n",
       "  9431,\n",
       "  93.0,\n",
       "  {'Item': 'UNKNOWN', 'Total Spent': '2.0'},\n",
       "  {'Item': 'UNKNOWN', 'Total Spent': '20.0'}),\n",
       " (9800,\n",
       "  9801,\n",
       "  93.0,\n",
       "  {'Item': 'nan', 'Total Spent': '2.0'},\n",
       "  {'Item': 'nan', 'Total Spent': '20.0'})]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Near Dupe Checker: \n",
    "\n",
    "def near_duplicate_checker(df, columns, threshold):\n",
    "    # Sorting to bring similar rows together\n",
    "    sorted_df = df.sort_values(by=columns).reset_index(drop=True)  \n",
    "    near_duplicates = []\n",
    "    \n",
    "    # For Loop to go through the dataset and find near duplicates based on the threshold specified\n",
    "    for i in range(len(sorted_df) - 1):\n",
    "        row1 = sorted_df.iloc[i][columns].astype(str).fillna('')\n",
    "        row2 = sorted_df.iloc[i + 1][columns].astype(str).fillna('')\n",
    "        \n",
    "        # Skipping exact duplicates\n",
    "        if row1.equals(row2):  \n",
    "            continue\n",
    "        \n",
    "        similarity_scores = [fuzz.ratio(row1[col], row2[col]) for col in columns]\n",
    "        avg_similarity = sum(similarity_scores) / len(columns)\n",
    "        \n",
    "        if avg_similarity >= threshold:\n",
    "            near_duplicates.append((i, i + 1, avg_similarity, row1.to_dict(), row2.to_dict()))\n",
    "    \n",
    "    if not near_duplicates:\n",
    "        print(\"No near duplicates found.\")\n",
    "    else:\n",
    "        print(f\"The near duplicate test program found {len(near_duplicates)} near duplicate row pairs for the columns {columns}. \\nHere are some examples:\")\n",
    "        for pair in near_duplicates[:5]:  # Show first 5 pairs\n",
    "            print(f\"\\nRow {pair[0]} ~ Row {pair[1]} (Similarity: {pair[2]:.2f}%)\")\n",
    "            print(\"Row 1:\", pair[3])  # Print first row\n",
    "            print(\"Row 2:\", pair[4])  # Print second row\n",
    "    \n",
    "    return near_duplicates\n",
    "\n",
    "# running the function here\n",
    "near_duplicate_checker(cafeSet, columns_to_check, threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion \n",
    "\n",
    "Overall, this comprehensive clean data checker provides a strucutred approach to data validation and data cleaning. By integrating the ten essential checks,data type verification, range validation, format enforcement, consistency analysis, uniqueness detection, presence checks, length constraints, look-up validation, and exact and near duplicate detection. The functions in the notebook effectively identify and highlight issues that are common in data science. This part of the assignment helped develop our skills as Data Scientists and has helped grow our python skills. \n",
    "\n",
    "### References\n",
    "1. Winter2025-CSI4142-Week4-DataQuality-Cleaning-Part1\n",
    "2. Winter2025-CSI4142-Week4-DataQuality-Cleaning-Part2\n",
    "- From these two slide decks of class content, we learned the different types of checks and general ideas about how to implement. \n",
    "3. https://medium.com/@alphaiterations/fuzzy-matching-with-fuzzywuzzy-a-comprehensive-guide-04873f07de31\n",
    "- This article helped with some information about FuzzyWuzzy, a python library we used for in Near Duplicate Check\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
